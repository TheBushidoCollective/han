---
name: han-memory-system
summary: Complete architecture and implementation of Han Memory - five-layer semantic memory with synthesis via Agent SDK, streaming output, and citation-backed answers
---

# Han Memory System

A five-layer memory system providing semantic search across rules, native summaries, transcripts, team memory (git), and external providers (GitHub) - synthesized via Agent SDK with streaming output and deep-linked citations to the Browse UI.

## Implementation Status

| Phase | Component | Status | Notes |
|-------|-----------|--------|-------|
| Phase 1 | Storage Layer | âœ… Complete | JSONL/YAML storage, paths |
| Phase 2 | Rules (file-based) | âœ… Complete | .claude/rules/ search |
| Phase 3 | Git Source Provider | âœ… Complete | Direct git log access |
| Phase 3b | Research Engine | âœ… Complete | "Research until confident" pattern |
| Phase 4 | Query Router (multi-layer racing) | âœ… Complete | Promise.all() parallel search |
| Phase 5 | Native Embeddings (SQLite + FTS5) | âœ… Complete | han-native with BM25 |
| Phase 6 | Auto-Promotion Engine | âœ… Complete | Pattern detection, promotion |
| Phase 7 | Transcript Indexing (FTS) | âœ… Complete | FTS index of session transcripts |
| Phase 8 | Vector Indexing Trigger | âœ… Complete | indexDocuments() auto-triggers vector indexing |
| Phase 9 | Hybrid Search (FTS + Vector) | âœ… Complete | hybridSearch() combines BM25 + vector |
| Phase 10 | Memory Agent (Agent SDK) | âœ… Complete | memory-agent.ts with read-only search |
| Phase 11 | Data Access Layer MCP | âœ… Complete | Direct search functions (searchMemoryLayers) |
| Phase 12 | Live Session Streaming | âœ… Complete | streaming.ts with PubSub + 100ms delay |
| Phase 13 | Browse UI Integration | âœ… Complete | SearchTab.tsx with GraphQL subscriptions |
| Phase 14 | Summaries (native Claude) | âœ… Complete | parseSummaries(), indexNativeSummaries(), searchNativeSummaries() |
| Phase 15 | GitHub Provider (via MCP) | âœ… Complete | searchExternalProviders() via provider-discovery.ts |

**Current State**: Memory Agent with live streaming is functional. All five layers (rules, summaries, transcripts, team, external providers) are searchable. Browse UI shows real-time progress (SEARCHING, FOUND, SYNTHESIZING) and final results with confidence levels and citations. GitHub PRs/issues are searchable when hashi-github is installed.

**Removed: Observations Layer** - Tool calls and intent are already captured in transcripts. Separate observation capture would duplicate data and create sync concerns. "Best sync is no sync."

## Phase 8: Vector Indexing Trigger

The embedding infrastructure is built but not triggered automatically. This phase wires up vector indexing alongside FTS:

```
Coordinator sees new JSONL lines
        â”‚
        â”œâ”€â–º Index to FTS (BM25)        â† Already works
        â”‚
        â””â”€â–º Index to Vector Store      â† Phase 8 adds this
                â”‚
                â”œâ”€â–º Generate embedding (ONNX Runtime)
                â””â”€â–º Store in sqlite-vec
```

**Implementation:**

1. Modify `indexDocuments()` in `indexer.ts` to also call vector indexing
2. Batch embeddings generation for efficiency (up to 32 docs at once)
3. Use the same document content for both FTS and vector
4. Handle graceful degradation if ONNX unavailable

## Phase 9: Hybrid Search

Combine FTS (keyword) and Vector (semantic) search results:

```typescript
async function hybridSearch(query: string, limit: number): Promise<SearchResult[]> {
  const [ftsResults, vectorResults] = await Promise.all([
    searchFts(tableName, query, limit * 2),
    vectorSearch(tableName, query, limit * 2),
  ]);

  // Reciprocal Rank Fusion to combine scores
  return fuseResults(ftsResults, vectorResults, limit);
}
```

## Vision

> **The best setup is no setup.**
> **The best sync is no sync.**
> **Just ask questions, get answers.**
> **Claude learns and writes, doesn't just suggest.**
> **See how the system thinks in real-time.**

Han Memory solves everything Claude Mem does AND more:

- Personal session continuity ("continue where I left off")
- Team knowledge ("who knows about payments?")
- Decision archaeology ("why did we choose X?")
- Permanent conventions (`.claude/rules/`)
- **Self-learning promotion** (patterns auto-promoted to rules)
- **Multi-layer racing** (search all layers in parallel)
- **Streaming synthesis** (see how Claude thinks while researching)
- **Citation links** (click to view source in Browse UI)

## Architecture

### Agent Isolation Pattern (CRITICAL)

The memory system uses a **separate Claude Code SDK agent** with **READ-ONLY access** to memory data. The main agent does NOT have direct access to memory data tools.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MAIN AGENT (User's Claude Code session)                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  â€¢ Has access to standard tools (Read, Write, Bash, etc.)       â”‚
â”‚  â€¢ Calls memory() MCP tool for memory queries                   â”‚
â”‚  â€¢ DOES NOT have direct access to memory data                   â”‚
â”‚  â€¢ Receives synthesized answers with citations                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                              â”‚ memory() tool call
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MEMORY AGENT (Claude Code SDK Agent - READ-ONLY)               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  â€¢ Spawned via Claude Agent SDK                                 â”‚
â”‚  â€¢ Session ID returned for live streaming                       â”‚
â”‚  â€¢ Has access to:                                               â”‚
â”‚    1. Data Access Layer MCP (local data)                        â”‚
â”‚    2. Memory Provider MCPs (hashi-github, etc.)                 â”‚
â”‚  â€¢ Cannot modify files, cannot execute code                     â”‚
â”‚  â€¢ Synthesizes information into meaningful answers              â”‚
â”‚  â€¢ Returns citations as deep links to Browse UI                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                                           â”‚
        â”‚ MCP tool calls                            â”‚ MCP tool calls
        â–¼                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HAN DATA-ACCESS-LAYER MCP    â”‚   â”‚  MEMORY PROVIDER MCPs       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚  Local data access ONLY:      â”‚   â”‚  External data sources:     â”‚
â”‚  â€¢ search_rules(query)        â”‚   â”‚  â€¢ hashi-github:            â”‚
â”‚  â€¢ search_transcripts(query)  â”‚   â”‚    search_prs, search_issuesâ”‚
â”‚  â€¢ search_git_history(query)  â”‚   â”‚  â€¢ hashi-gitlab:            â”‚
â”‚  â€¢ search_observations(query) â”‚   â”‚    search_mrs, search_issuesâ”‚
â”‚  â€¢ get_session(id)            â”‚   â”‚  â€¢ Future: notion, etc.     â”‚
â”‚  â€¢ get_commit(sha)            â”‚   â”‚                             â”‚
â”‚                               â”‚   â”‚  Memory Agent calls these   â”‚
â”‚  All tools READ-ONLY.         â”‚   â”‚  directly, not via DAL.     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Live Session Streaming

When a memory query is initiated (from Browse UI or han MCP), the Memory Agent session is **attachable** for live feedback:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BROWSE UI or HAN MCP                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  1. Call memory(question)                                       â”‚
â”‚  2. Receive session_id immediately                              â”‚
â”‚  3. Attach to session for live streaming                        â”‚
â”‚  4. See agent's "thinking" in real-time:                        â”‚
â”‚     ğŸ” Searching rules...                                       â”‚
â”‚     ğŸ“š Found: api.md mentions rate limiting                     â”‚
â”‚     ğŸ” Searching transcripts...                                 â”‚
â”‚     ğŸ’¬ Found: Discussion about 429 errors                       â”‚
â”‚     ğŸ” Querying GitHub PRs...                                   â”‚
â”‚     ğŸ“ Found: PR #42 added rate limit middleware                â”‚
â”‚     âœ¨ Synthesizing answer...                                   â”‚
â”‚  5. Receive final answer with citations                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The experience is identical whether initiated from:

- **Browse UI**: Memory search page with live streaming panel
- **han MCP**: memory() tool returns session_id for streaming

### Why Agent Isolation?

1. **Security**: Memory data includes sensitive session history. Isolating to a read-only agent prevents accidental modifications.
2. **Consistency**: The memory agent always behaves the same way - it can only read and synthesize, never act.
3. **Reliability**: No fallback architecture needed. The agent either gets data or doesn't - consistent behavior.
4. **Separation of Concerns**: Main agent handles actions, memory agent handles knowledge retrieval.
5. **Observability**: Session attachment enables live feedback - see how the agent "thinks" while searching.

### Memory Agent MCP Configuration

The Memory Agent uses the Claude Agent SDK with **restricted tool access** - it can ONLY use MCP tools, not standard Claude Code tools like Bash, Read, or Write. This is enforced via the `allowedTools` parameter.

#### MCP Server Sources

**ALL Memory Agent MCP servers are discovered from plugins** via a single, unified mechanism. Plugins must have BOTH `mcp` AND `memory` keys in their `han-plugin.yml` to be discovered as memory providers.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MEMORY PROVIDER MCPs (All Plugin-Discovered)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â”‚  Discovery: Scan installed plugins' han-plugin.yml              â”‚
â”‚  Requirement: Plugin must have BOTH `mcp` AND `memory` keys     â”‚
â”‚                                                                 â”‚
â”‚  Core Providers (from core/han-plugin.yml):                     â”‚
â”‚    - memory-dal: Internal database (FTS, vector, hybrid search) â”‚
â”‚                                                                 â”‚
â”‚  Hashi Providers (from hashi-*/han-plugin.yml):                 â”‚
â”‚    - blueprints: Project documentation search                   â”‚
â”‚    - github: PRs, issues, code search                           â”‚
â”‚    - gitlab: MRs, issues                                        â”‚
â”‚    - (future: notion, confluence, etc.)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This unified discovery mechanism means:

- No hardcoded MCP servers in the Memory Agent code
- New providers are added by installing plugins, not modifying agent code
- Each plugin declares its own MCP config and allowed tools

#### Plugin-Based Memory Provider Discovery

Memory providers are discovered from installed Han plugins that have BOTH an `mcp` key (defining the MCP server) AND a `memory` key (defining which tools are allowed for memory queries).

**han-plugin.yml Structure:**

MCP servers can be defined in two places:

- `mcp_servers` (root) - available to Claude Code AND memory system
- `memory.mcp_servers` - memory-only MCP servers (not exposed to Claude Code)

```yaml
# Example 1: core/han-plugin.yml (shared MCP server)
# MCP servers available to Claude Code AND memory system
mcp_servers:
  memory-dal:
    name: memory-dal
    description: Han internal memory database with FTS and vector search
    command: han
    args: ["mcp", "memory"]

# Memory config - defines which tools the Memory Agent can use
memory:
  allowed_tools:
    - mcp__memory-dal__memory_search_fts
    - mcp__memory-dal__memory_search_vector
    - mcp__memory-dal__memory_search_hybrid
    - mcp__memory-dal__memory_list_layers
  system_prompt: |
    Search the internal Han memory database for relevant information.
```

```yaml
# Example 2: Memory-only MCP server (not exposed to Claude Code)
memory:
  # MCP servers ONLY for memory system
  mcp_servers:
    internal-search:
      command: han
      args: ["mcp", "internal-search"]
  allowed_tools:
    - mcp__internal-search__search
  system_prompt: |
    Search internal data sources.
```

**Discovery Logic:**

```typescript
// Pseudocode for provider discovery
async function discoverMemoryProviders(): Promise<MemoryProvider[]> {
  const providers: MemoryProvider[] = [];

  for (const plugin of installedPlugins) {
    const config = parseYaml(plugin.hanPluginYml);

    // Plugin must have memory.allowed_tools
    if (!config.memory?.allowed_tools?.length) continue;

    // Collect MCP servers from BOTH sources:
    // 1. Root mcp_servers - available to Claude Code AND memory
    // 2. memory.mcp_servers - memory-only MCP servers
    const allMcpServers = {
      ...config.mcp_servers,        // Available to Claude Code
      ...config.memory.mcp_servers, // Memory-only
    };

    // Create provider for each server with matching tools
    for (const [serverKey, serverConfig] of Object.entries(allMcpServers)) {
      const serverTools = config.memory.allowed_tools.filter(
        tool => tool.startsWith(`mcp__${serverKey}__`)
      );

      if (serverTools.length > 0) {
        providers.push({
          name: plugin.name,
          type: "mcp",
          mcpConfig: serverConfig,
          allowedTools: serverTools,
        });
      }
    }
  }

  return providers;
}
```

#### Tool Restriction via allowedTools

The Memory Agent is spawned with an explicit `allowedTools` array, preventing access to any tools not in the list:

```typescript
// memory-agent.ts
const { mcpServers, allowedTools } = await buildMemoryAgentMcpConfig();

const agent = query({
  prompt: synthesisPrompt,
  options: {
    model: "claude-sonnet-4-20250514",
    maxTurns: 10,
    mcpServers,
    allowedTools,  // CRITICAL: Only these tools are available
  },
});
```

**What's Allowed** (dynamically from discovered plugins):

- `mcp__memory-dal__memory_search_fts` (from core)
- `mcp__memory-dal__memory_search_hybrid` (from core)
- `mcp__github__list_pull_requests` (from hashi-github, if installed)
- Any tool listed in `memory.allowed_tools` of discovered plugins

**What's Blocked:**

- `Bash` (no shell access)
- `Read` / `Write` (no file access)
- `Edit` (no file modification)
- Any tool not explicitly in the allowedTools array

This ensures the Memory Agent is truly read-only and can only synthesize information from its connected MCP servers. The tool list is fully dynamic - adding a new memory provider plugin automatically makes its tools available.

### Data Layers (4 Layers)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: Rules (.claude/rules/ or ~/.claude/rules/)            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  FILE-BASED: Project-level or user-level conventions            â”‚
â”‚  Git-tracked, team-reviewed, highest authority                  â”‚
â”‚  â†‘ AUTO-PROMOTED from patterns when confidence >= 0.8           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 2: Summaries (Claude message summary type)               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  USE NATIVE: Claude Code's built-in summary messages            â”‚
â”‚  No custom summarization needed - leverage the platform         â”‚
â”‚  "What was I working on?" â†’ Recent session context              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 3: Transcripts (~/.claude/projects/{id}/sessions/)       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  INDEXED: Full conversation history with Claude                 â”‚
â”‚  Contains tool calls, results, intent, reasoning - everything   â”‚
â”‚  No separate "observations" needed - it's all here              â”‚
â”‚  âš ï¸ SYNC CONCERN: Handle disk deletion vs DB retention          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 4: Providers (MCP memory functions)                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  EXTENSIBLE: MCP functions calling external memory providers    â”‚
â”‚  Git commits, PRs, Issues, external knowledge bases             â”‚
â”‚  Plugin-based: hashi-github, hashi-gitlab, etc.                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **Note**: Observations layer was removed. Tool calls, results, and intent are already in transcripts. Duplicating this data would violate "best sync is no sync."

## Layer Mapping (Source of Truth)

| Layer | Source | Implementation |
|-------|--------|----------------|
| **Rules** | `.claude/rules/` (project) or `~/.claude/rules/` (user) | File-based, git-tracked |
| **Summaries** | Claude Code's message `summary` type | Native platform feature |
| **Observations** | Pre-tool use context | Intent capture before action |
| **Transcripts** | `~/.claude/projects/{projectId}/sessions/*.jsonl` | Indexed from disk |
| **Providers** | MCP tool calls | External memory via plugins |

## Transcript/Database Sync Concern

**Problem**: Conversations may be removed from disk (user deletion, cleanup) but remain indexed in the database.

**Solution**:

1. **Soft References**: Index stores session_id + file_path; query validates file exists before returning
2. **Periodic Reconciliation**: Background task compares indexed sessions against disk
3. **Lazy Cleanup**: On query, if source file missing, mark as stale and exclude
4. **User Control**: Provide `han memory gc` command to purge orphaned index entries

```typescript
// On transcript search
for (const result of indexResults) {
  if (!existsSync(result.sourcePath)) {
    markAsStale(result.id);  // Background cleanup
    continue;  // Don't return stale results
  }
  validResults.push(result);
}
```

## Multi-Layer Racing (Key Architecture)

**The memory system searches ALL layers in parallel**, not just one layer based on keyword classification.

### Old (Broken) Approach

```
Question â†’ Classify by keywords â†’ Pick ONE layer â†’ Search â†’ Low confidence? Too bad.
```

Problems with keyword routing:

- "How do we handle X" â†’ âœ… matches "conventions"
- "How do engagements work" â†’ âŒ doesn't match (no "we")
- "What production issues?" â†’ âŒ doesn't match any pattern

### New (Racing) Approach

```
Question â†’ Search ALL layers in parallel â†’ Combine results â†’ Return best matches
```

The `searchAllLayers()` function:

1. Races all layers concurrently using `Promise.all()`
2. Each layer returns results with confidence scores
3. Results are combined with source attribution
4. Best matches are returned regardless of which layer found them

### Layer Priority

When multiple layers have content:

1. **Rules** (highest authority - git-tracked conventions)
2. **Transcripts** (conversation history)
3. **Team Memory** (git/PRs)

### Result Format

```typescript
interface MemoryResult {
  answer: string;
  source: "rules" | "team" | "transcripts" | "combined";
  confidence: "high" | "medium" | "low";
  citations: Citation[];
  layersSearched: MemoryLayer[];  // Shows which layers were searched
}
```

## Native Backend Architecture

The memory system uses a pure-Rust native module (`han-native`) for cross-compilation compatibility:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  han-native (Rust, napi-rs)                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SQLite (rusqlite)              â”‚  ONNX Runtime (ort)           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
â”‚  â€¢ FTS5 with BM25 scoring       â”‚  â€¢ load-dynamic feature       â”‚
â”‚  â€¢ sqlite-vec for vectors       â”‚  â€¢ all-MiniLM-L6-v2 model     â”‚
â”‚  â€¢ WAL mode for concurrency     â”‚  â€¢ Runtime download on first  â”‚
â”‚  â€¢ Single unified database      â”‚    use (~150MB + 90MB model)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  reqwest (rustls-tls)           â”‚  Storage Location             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  â€¢ Pure Rust TLS                â”‚  ~/.claude/han/han.db         â”‚
â”‚  â€¢ Downloads ONNX Runtime       â”‚  ~/Library/Caches/han/        â”‚
â”‚  â€¢ Downloads embedding model    â”‚    onnxruntime/, models/      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Design Decisions:**

- **SQLite over SurrealDB**: Simpler, more portable, better tooling
- **No OpenSSL**: Uses rustls for TLS, enabling Linux cross-compilation
- **No link-time ONNX**: Uses `load-dynamic` to download ONNX Runtime at runtime
- **sqlite-vec**: Pure Rust vector extension, avoids aws-lc-sys issues
- **Single binary**: All dependencies bundled, ONNX/model downloaded on first use

## Embeddings Generation Pipeline

The embedding system uses ONNX Runtime with the `all-MiniLM-L6-v2` model for semantic similarity:

### Model Details

| Property | Value |
|----------|-------|
| Model | `all-MiniLM-L6-v2` (Sentence Transformers) |
| Dimensions | 384 |
| Max Sequence | 512 tokens |
| Source | HuggingFace |
| Size | ~90MB model + ~150MB ONNX Runtime |

### Embedding Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. FIRST USE: Download Dependencies                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚  â€¢ Check ~/Library/Caches/han/onnxruntime/ for ONNX Runtime     â”‚
â”‚  â€¢ Download platform-specific build if missing (v1.20.1)        â”‚
â”‚    - macOS: onnxruntime-osx-arm64-1.20.1.tgz                   â”‚
â”‚    - Linux: onnxruntime-linux-x64-1.20.1.tgz                   â”‚
â”‚    - Windows: onnxruntime-win-x64-1.20.1.zip                   â”‚
â”‚  â€¢ Download model.onnx and tokenizer.json from HuggingFace      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. TOKENIZATION                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚  â€¢ Load tokenizer.json with vocab, special tokens               â”‚
â”‚  â€¢ Add [CLS] token at start                                     â”‚
â”‚  â€¢ Tokenize text: lowercase, split on whitespace/punctuation    â”‚
â”‚  â€¢ Look up token IDs in vocab, use [UNK] for unknown            â”‚
â”‚  â€¢ Add [SEP] token at end                                       â”‚
â”‚  â€¢ Pad to 512 tokens with [PAD]                                 â”‚
â”‚  â€¢ Generate attention mask (1s for real tokens, 0s for padding) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. INFERENCE                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                â”‚
â”‚  â€¢ Create session with ONNX model (GraphOptimizationLevel::3)   â”‚
â”‚  â€¢ Prepare inputs: input_ids, attention_mask, token_type_ids    â”‚
â”‚  â€¢ Run inference through transformer layers                     â”‚
â”‚  â€¢ Output: (batch_size, hidden_size=384) sentence embeddings    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. NORMALIZATION                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚  â€¢ Compute L2 norm: sqrt(sum(x_i^2))                            â”‚
â”‚  â€¢ Normalize each dimension: x_i / norm                         â”‚
â”‚  â€¢ Result: unit vectors for cosine similarity via dot product   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Vector Storage (sqlite-vec)

```sql
-- Vector table creation
CREATE VIRTUAL TABLE {table}_vec USING vec0(
    doc_id TEXT PRIMARY KEY,
    content TEXT,
    metadata TEXT,
    embedding float[384]
);

-- Vector search (KNN)
SELECT doc_id, content, metadata, distance
FROM {table}_vec
WHERE embedding MATCH ?query_blob
ORDER BY distance
LIMIT ?limit;
```

The vector is stored as a binary blob (384 floats * 4 bytes = 1536 bytes per vector).

### Search Modes

| Mode | Storage | Scoring | Use Case |
|------|---------|---------|----------|
| FTS (BM25) | `{table}_fts` | Term frequency + IDF | Keyword matching |
| Vector | `{table}_vec` | Cosine similarity | Semantic similarity |
| Hybrid | Both | Combine scores | Best of both |

Currently, the memory system uses both modes in parallel and combines results based on confidence scores

## MCP Tools

### `memory` (Unified Query - Spawns Memory Agent)

**Primary entry point for all memory queries.** Spawns a Memory Agent session and returns session_id for live streaming.

```typescript
interface MemoryParams {
  question: string;
}

interface MemoryResponse {
  session_id: string;      // Attach to this for live streaming
  answer: string;          // Final synthesized answer
  confidence: "high" | "medium" | "low";
  citations: Citation[];   // Deep links to Browse UI
  searched_sources: string[];
}
```

For most questions, uses multi-layer racing. Only personal questions ("what was I working on?") are routed specifically to personal memory.

### `team_query` (Team Memory Research)

Direct access to team memory research engine.

```typescript
interface TeamQueryParams {
  question: string;
  limit?: number;  // Default: 10
}
```

Uses "research until confident" pattern to search:

- Git commits and diffs
- PR descriptions and reviews
- Indexed observations

### `learn` (Capture Conventions)

Proactively capture learnings to `.claude/rules/`.

```typescript
interface LearnParams {
  domain: string;    // e.g., "testing", "api", "auth"
  content: string;   // The learning to capture
  scope?: "project" | "user";
}
```

### `auto_learn` (Self-Learning Visibility)

Check status and trigger pattern promotion.

```typescript
interface AutoLearnParams {
  action: "status" | "candidates" | "promote";
}
```

- **status**: View tracked patterns and statistics
- **candidates**: See patterns ready for promotion
- **promote**: Manually trigger promotion cycle

### Data Access Layer MCP (Memory Agent Only)

These tools are exposed **only to the Memory Agent**, not to the main agent:

```typescript
// Local data search tools
search_rules(query: string): Promise<RuleResult[]>
search_transcripts(query: string, limit?: number): Promise<TranscriptResult[]>
search_git_history(query: string, limit?: number): Promise<GitResult[]>
search_observations(query: string, limit?: number): Promise<ObservationResult[]>

// Specific item retrieval
get_session(session_id: string): Promise<Session>
get_commit(sha: string): Promise<Commit>
get_rule(domain: string): Promise<Rule>
```

All tools are **READ-ONLY**. The Memory Agent cannot modify any data through these tools.

### Session Streaming (Browse UI / MCP)

Attach to a Memory Agent session for live feedback:

```typescript
// From Browse UI (GraphQL subscription)
subscription MemoryAgentStream($sessionId: ID!) {
  memoryAgentMessages(sessionId: $sessionId) {
    type    # "thinking" | "tool_call" | "result" | "answer"
    content
    timestamp
  }
}

// From han MCP (streaming response)
interface MemoryStreamEvent {
  type: "thinking" | "tool_call" | "result" | "answer";
  content: string;
  tool?: string;        // For tool_call events
  source?: string;      // For result events
}
```

## Auto-Promotion Engine

The self-learning system that **actively writes** to `.claude/rules/` instead of just suggesting.

### Promotion Criteria

Patterns are automatically promoted when they meet:

- **3+ occurrences** across different sources
- **0.8+ confidence** score (starts at 0.5, gains 0.15 per occurrence)
- **Multiple authors** (bonus: increases confidence by 0.1)
- **Not already documented** in rules

### Domain Detection

Patterns are classified into domains based on keywords:

| Domain | Keywords |
|--------|----------|
| testing | test, spec, mock, fixture, assert, expect |
| api | endpoint, route, handler, request, response |
| auth | auth, login, session, token, jwt, oauth |
| database | db, query, migration, schema, model, orm |
| error | error, exception, catch, throw, handle |
| logging | log, logger, debug, info, warn |
| config | config, env, environment, settings |
| build | build, compile, bundle, webpack, vite |
| commands | command, cli, script, npm, bun |

### Integration Points

- **After research**: `learnFromResearch()` extracts patterns from evidence
- **After indexing**: `learnFromObservations()` extracts patterns from observations
- **Manual trigger**: `auto_learn` MCP tool with `action: "promote"`

## Storage Layout

```
~/.claude/
  han/
    memory/
      personal/
        sessions/
          {date}-{session_id}.jsonl    # Raw observations (append-only)
        summaries/
          {date}-{session_id}.yaml     # AI-compressed summaries
      
      # Note: Memory index is now unified in ~/.claude/han/han.db
      
      projects/
        github.com_org_repo/            # Denormalized git remote path
          meta.yaml                     # Index metadata, source cursors
    
    onnxruntime/                        # Downloaded ONNX Runtime
      onnxruntime-v1.20.1/
        lib/
          libonnxruntime.dylib          # Platform-specific library
    
    models/
      all-MiniLM-L6-v2/                 # Downloaded embedding model
        model.onnx
        tokenizer.json
          
.claude/                                # In project repo (git-tracked)
  rules/                                # Permanent wisdom - AUTO-PROMOTED
    api.md
    testing.md
    auth.md
```

## Hooks

| Hook | Event | File | Purpose |
|------|-------|------|---------|
| memory-summarize | Stop | `summarize.ts` | AI summarize session |
| memory-context | SessionStart | `context-injection.ts` | Inject continuity context |

## Core Components

### Multi-Layer Search (`lib/commands/mcp/memory-router.ts`)

The `searchAllLayers()` function races all layers:

```typescript
async function searchAllLayers(question: string): Promise<MemoryResult> {
  const [rulesResult, transcriptsResult, teamResult] = await Promise.all([
    searchRules(question),
    searchTranscripts(question),
    searchTeamMemory(question),
  ]);
  
  // Combine results, prioritize by layer authority
  return combineResults([rulesResult, transcriptsResult, teamResult]);
}
```

### Research Engine (`lib/memory/research.ts`)

Implements "research until confident" pattern:

1. Generate initial search query from question
2. Execute semantic search on indexed observations
3. Assess confidence based on evidence
4. If not confident, refine query and iterate
5. **Extract and track patterns from evidence**
6. Return answer with citations and caveats

### Auto-Promotion Engine (`lib/memory/promotion.ts`)

Implements self-learning pattern detection and promotion:

- `trackPattern()` - Track patterns in session store
- `getPromotionCandidates()` - Find patterns meeting criteria
- `promotePattern()` - Write to `.claude/rules/{domain}.md`
- `autoPromotePatterns()` - Promote all ready patterns
- `learnFromResearch()` - Learn after research completes
- `learnFromObservations()` - Learn after indexing

### Vector Store (`lib/memory/vector-store.ts`)

Native embeddings layer using han-native:

- Uses `han-native` for ONNX Runtime embeddings (all-MiniLM-L6-v2, 384 dimensions)
- SQLite with sqlite-vec for vector storage
- Cosine similarity search via KNN
- Zero-config: downloads ONNX/model on first use
- Graceful fallback if native module unavailable

### FTS Indexer (`lib/memory/indexer.ts`)

Full-text search layer using han-native:

- SQLite FTS5 with BM25 scoring
- Indexes observations, summaries, transcripts, team memory
- Per-project table namespacing

### Source Providers

**Git Provider** (`lib/memory/providers/git.ts`):

- Extracts commit messages and diffs
- Identifies file changes and patterns
- Maps authors to expertise areas

**GitHub Provider** (`lib/memory/providers/github.ts`):

- Requires `hashi-github` MCP server
- Extracts PR descriptions, reviews, comments
- Links commits to PR context

## Key Files

```
packages/han/
  lib/
    memory/
      storage.ts         # JSONL/YAML storage layer
      paths.ts           # Path resolution (personal, project)
      research.ts        # Research engine (research until confident)
      promotion.ts       # Auto-promotion engine (self-learning)
      capture.ts         # PostToolUse hook for observation capture
      summarize.ts       # Stop hook for session summarization
      context-injection.ts # SessionStart hook for continuity
      vector-store.ts    # Native embeddings layer (SQLite + ONNX)
      indexer.ts         # FTS indexer (SQLite FTS5 + BM25)
      types.ts           # Type definitions
      index.ts           # Module exports
      providers/
        git.ts           # Git source provider
        github.ts        # GitHub source provider (via MCP)
      
    commands/mcp/
      memory-router.ts   # Unified memory tool (multi-layer racing)
      team-memory.ts     # Team query tool
      auto-learn.ts      # Auto-learn status/trigger tool
      memory.ts          # Learn tool and memory file utilities
      server.ts          # MCP server with all tools

packages/han-native/
  src/
    lib.rs              # Main exports, file utilities
    db.rs               # SQLite wrapper (FTS5 + sqlite-vec)
    embedding.rs        # ONNX Runtime embeddings
    download.rs         # Runtime download manager
```

## Test Coverage

- `memory-storage.test.ts`: Storage layer tests
- `memory-router.test.ts`: Query classification and multi-layer search tests (99 tests)
- `mcp-team-memory.test.ts`: Team query MCP tool tests
- `research.test.ts`: Research engine tests
- `promotion.test.ts`: Auto-promotion engine tests (25 tests)

## Self-Learning Philosophy

> **Claude should actively learn, not just suggest.**

The auto-promotion system is:

- **Low-stakes**: Git-tracked, reviewable, revertible
- **Additive**: Only adds new rules, never modifies existing
- **Conservative**: High thresholds prevent noise
- **Transparent**: All promotions visible in git history

## Synthesis Layer (Agent SDK)

The synthesis layer is the "brain" that makes all the data meaningful. Instead of just returning raw results from each layer, it uses the Agent SDK to:

1. **Collect** - Query all memory layers in parallel
2. **Synthesize** - Understand intent and combine relevant information
3. **Stream** - Output reasoning in real-time for user visibility
4. **Cite** - Link every claim to its source in Browse UI

### Architecture

```typescript
import Anthropic from "@anthropic-ai/sdk";

interface SynthesisResult {
  answer: string;
  citations: Array<{
    text: string;
    source: MemoryLayer;
    browseUrl: string;  // Deep link: /sessions/{id}#msg-{idx}
  }>;
  reasoning: string[];  // Streamed thinking steps
}

async function synthesizeMemory(
  question: string,
  onChunk: (text: string) => void  // Streaming callback
): Promise<SynthesisResult> {
  // 1. Race all layers
  const [rules, summaries, observations, transcripts, providers] =
    await Promise.all([
      searchRules(question),
      searchSummaries(question),
      searchObservations(question),
      searchTranscripts(question),
      queryProviders(question),
    ]);

  // 2. Synthesize with Agent SDK
  const client = new Anthropic();
  const stream = client.messages.stream({
    model: "claude-sonnet-4-20250514",
    max_tokens: 4096,
    messages: [{
      role: "user",
      content: buildSynthesisPrompt(question, {
        rules, summaries, observations, transcripts, providers
      })
    }]
  });

  // 3. Stream output for live feedback
  const reasoning: string[] = [];
  for await (const event of stream) {
    if (event.type === "content_block_delta") {
      const text = event.delta.text;
      onChunk(text);  // Send to UI immediately
      reasoning.push(text);
    }
  }

  // 4. Parse citations from response
  const citations = extractCitations(reasoning.join(""));

  return { answer: reasoning.join(""), citations, reasoning };
}
```

### Streaming Output

When invoked from Browse UI or MCP, the user sees Claude's reasoning in real-time:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” Searching rules...                                          â”‚
â”‚  ğŸ“š Found: api.md mentions rate limiting                        â”‚
â”‚  ğŸ” Searching transcripts...                                    â”‚
â”‚  ğŸ’¬ Found: Discussion about 429 errors in session abc123        â”‚
â”‚  ğŸ” Querying git history...                                     â”‚
â”‚  ğŸ“ Found: PR #42 added rate limit middleware                   â”‚
â”‚                                                                 â”‚
â”‚  âœ¨ Synthesizing answer...                                      â”‚
â”‚                                                                 â”‚
â”‚  Based on your project's conventions and history, rate limiting â”‚
â”‚  is handled by the middleware in src/api/rateLimit.ts [1].      â”‚
â”‚  This was added in PR #42 [2] after discussions about 429       â”‚
â”‚  errors [3].                                                    â”‚
â”‚                                                                 â”‚
â”‚  [1] .claude/rules/api.md                                       â”‚
â”‚  [2] github.com/org/repo/pull/42                                â”‚
â”‚  [3] /sessions/abc123#msg-15  â† Click to view in Browse         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Citation Deep Links

Every citation links directly to the source in Browse UI:

| Source | URL Pattern | Example |
|--------|-------------|---------|
| Rules | `/memory?tab=rules&file={domain}` | `/memory?tab=rules&file=api` |
| Transcripts | `/sessions/{sessionId}#msg-{index}` | `/sessions/abc123#msg-15` |
| Git Commits | `/repos/{repoId}?commit={sha}` | External: GitHub/GitLab |
| PRs | External link | `github.com/org/repo/pull/42` |
| Observations | `/sessions/{sessionId}?view=observations` | `/sessions/abc123?view=observations` |

### Pre-Tool Observations (Layer 3)

Observations capture **intent**, not just action. Instead of logging "Read file X", capture:

```typescript
interface Observation {
  // What Claude was trying to accomplish
  intent: string;  // "Understanding how auth middleware validates tokens"

  // The tool used
  tool: string;    // "Read"
  input: object;   // { file_path: "src/auth/middleware.ts" }

  // Why this became meaningful (post-hoc)
  significance?: string;  // "Led to discovering JWT validation bug"

  timestamp: string;
}
```

This enables richer pattern detection:

- "Authentication investigations often start with middleware.ts"
- "Payment debugging usually involves 3+ file reads before success"

### Native Summaries (Layer 2)

Instead of custom summarization, leverage Claude Code's built-in message summary type:

```typescript
// Claude Code transcript message types
type MessageType = "user" | "assistant" | "summary";

// A summary message in the transcript
{
  type: "summary",
  message: {
    content: "Session focused on refactoring auth module...",
    context_window_compression: true
  },
  timestamp: "2025-01-15T10:30:00Z"
}
```

Benefits:

- No custom summarization logic needed
- Summaries already optimized for context compression
- Consistent with Claude Code's internal model

### Provider Plugin Interface

External memory providers are MCP functions that conform to this interface:

```typescript
interface MemoryProvider {
  name: string;           // "github", "gitlab", "notion"
  query(question: string): Promise<ProviderResult>;
}

interface ProviderResult {
  results: Array<{
    content: string;
    source: string;       // URL or identifier
    author?: string;
    timestamp?: string;
    confidence: number;   // 0-1
  }>;
  metadata: {
    queryTime: number;
    resultCount: number;
  };
}
```

Providers are discovered via installed hashi-* plugins:

- `hashi-github` â†’ GitHub PRs, Issues, Discussions
- `hashi-gitlab` â†’ GitLab MRs, Issues
- `hashi-notion` â†’ Notion pages (future)
- `hashi-confluence` â†’ Confluence docs (future)
